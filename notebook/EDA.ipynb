{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T16:06:05.031633Z",
     "start_time": "2019-10-18T16:06:04.884920Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import re\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from IPython.core.display import HTML, display\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import MeCab\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.17.2\n",
      "pandas version: 0.25.1\n",
      "seaborn version: 0.9.0\n",
      "matploblib version: 3.1.1\n",
      "lightgbm version: 2.3.0\n",
      "sklearn version: 0.21.3\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"seaborn version:\", sns.__version__)\n",
    "print(\"matploblib version:\", matplotlib.__version__)\n",
    "print(\"lightgbm version:\", lgb.__version__)\n",
    "print(\"sklearn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理(文字列系)\n",
    "\n",
    "# カラム名を変更\n",
    "def rename_cols(df):\n",
    "    df = df.rename(columns={\"賃料\": \"target\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "# 面積\n",
    "def pre_area(df):\n",
    "    df.loc[:, \"area\"] = df[\"面積\"].str.replace(\"m2\", \"\").astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 築年数\n",
    "def pre_age(df):\n",
    "    df.loc[:, \"age\"] = (\n",
    "        df[\"築年数\"].str.replace(\"新築\", \"0\").str.replace(\"年[1,2]ヶ月\", \"\").astype(int)\n",
    "    )\n",
    "    # 520年とか明らかに間違っているデータがあるがこれは100にしちゃう\n",
    "    df.loc[df.age > 100, \"age\"] = 100\n",
    "    return df\n",
    "\n",
    "\n",
    "# 方角\n",
    "def pre_direction(df):\n",
    "    df.loc[:, \"direction\"] = df[\"方角\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "# 区\n",
    "def pre_ward(df):\n",
    "    # oo区\n",
    "    df.loc[:, \"ward\"] = df[\"所在地\"].str.replace(\"東京都\", \"\").str.split(\"区\", expand=True)[0]\n",
    "    # oo区oo\n",
    "    df.loc[:, \"ward_detail\"] = (\n",
    "        df[\"所在地\"].str.replace(\"東京都\", \"\").str.split(r\"\\d\", n=1, expand=True).iloc[:, 0]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# 間取り\n",
    "def pre_madori(df):\n",
    "    df.loc[:, \"nando\"] = df[\"間取り\"].str.contains(\"納戸\").astype(int)\n",
    "    df.loc[:, \"madori\"] = df[\"間取り\"].str.replace(\"(納戸)\", \"\").str.replace(\"+\", \"\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# キッチン\n",
    "def pre_kitchen(df):\n",
    "    for kitchen_col_name in pd.Series(\n",
    "        df[\"キッチン\"].str.replace(\"／\", \"\").str.split(\"\\t\", expand=True).values.flatten()\n",
    "    ).unique():\n",
    "        if (\n",
    "            kitchen_col_name\n",
    "            and type(kitchen_col_name) == str\n",
    "            and kitchen_col_name != \"\"\n",
    "        ):\n",
    "            df.loc[:, kitchen_col_name] = (\n",
    "                df[\"キッチン\"].fillna(\"\").str.contains(kitchen_col_name).astype(int)\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "# バス・トイレ\n",
    "def pre_bath(df):\n",
    "    for bath_col_name in pd.Series(\n",
    "        df[\"バス・トイレ\"].str.replace(\"／\", \"\").str.split(\"\\t\", expand=True).values.flatten()\n",
    "    ).unique():\n",
    "        if (\n",
    "            bath_col_name\n",
    "            and type(bath_col_name) == str\n",
    "            and bath_col_name != \"\"\n",
    "            and bath_col_name != \"トイレなし\"\n",
    "        ):\n",
    "            df.loc[:, bath_col_name] = (\n",
    "                df[\"バス・トイレ\"].fillna(\"\").str.contains(bath_col_name).astype(int)\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "# 室内設備\n",
    "def pre_room_equip(df):\n",
    "    for bath_col_name in pd.Series(\n",
    "        df[\"室内設備\"].str.replace(\"／\", \"\").str.split(\"\\t\", expand=True).values.flatten()\n",
    "    ).unique():\n",
    "        if bath_col_name and type(bath_col_name) == str and bath_col_name != \"\":\n",
    "            df.loc[:, bath_col_name] = (\n",
    "                df[\"室内設備\"].fillna(\"\").str.contains(bath_col_name).astype(int)\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "# 放送・通信\n",
    "def pre_comm(df):\n",
    "    for comm_col_name in pd.Series(\n",
    "        df[\"放送・通信\"].str.replace(\"／\", \"\").str.split(\"\\t\", expand=True).values.flatten()\n",
    "    ).unique():\n",
    "        if comm_col_name and type(comm_col_name) == str and comm_col_name != \"\":\n",
    "            df.loc[:, comm_col_name] = (\n",
    "                df[\"放送・通信\"].fillna(\"\").str.contains(comm_col_name).astype(int)\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "# 契約期間\n",
    "def pre_contract_period(df):\n",
    "    df.loc[:, \"contract_period\"] = df[\"契約期間\"].map(\n",
    "        lambda x: np.nan\n",
    "        if type(x) == float or \"まで\" in x\n",
    "        else x.replace(\"※この物件は\\t定期借家\\tです。\", \"\").replace(\"\\t\", \"\").replace(\"間\", \"\")\n",
    "    )\n",
    "\n",
    "    def contract_period_to_float(x):\n",
    "        if type(x) == float:\n",
    "            return x\n",
    "\n",
    "        elif len(x.split(\"年\")) == 2 and x.split(\"年\")[1] == \"\":\n",
    "            return float(x.replace(\"年\", \"\"))\n",
    "\n",
    "        elif len(x.split(\"ヶ月\")) == 2 and x.split(\"ヶ月\")[1] == \"\" and \"年\" not in x:\n",
    "            return float(x.replace(\"ヶ月\", \"\")) / 12\n",
    "\n",
    "        else:\n",
    "            return (\n",
    "                float(x.split(\"年\")[0]) + float(x.split(\"年\")[1].replace(\"ヶ月\", \"\")) / 12\n",
    "            )\n",
    "\n",
    "    df.loc[:, \"contract_period\"] = df[\"contract_period\"].map(contract_period_to_float)\n",
    "    df.loc[:, \"teiki_shakuya\"] = (\n",
    "        df[\"契約期間\"]\n",
    "        .str.contains(\"定期借家\")\n",
    "        .map(lambda x: np.nan if type(x) == float else float(x))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# アクセス\n",
    "def pre_access(df):\n",
    "    # アクセスに関する列を抽出\n",
    "    df_access = df[\"アクセス\"].str.split(\"\\t\", expand=True)[[0, 1, 2, 4, 5, 6, 8, 9, 10]]\n",
    "\n",
    "    df_access.columns = [\n",
    "        \"line_1\",\n",
    "        \"station_1\",\n",
    "        \"duration_1\",\n",
    "        \"line_2\",\n",
    "        \"station_2\",\n",
    "        \"duration_2\",\n",
    "        \"line_3\",\n",
    "        \"station_3\",\n",
    "        \"duration_3\",\n",
    "    ]\n",
    "\n",
    "    # 1つめの最寄り駅がバス/車の場合はNaNに\n",
    "    df_access.loc[:, \"duration_1\"] = df_access.loc[:, \"duration_1\"].str.replace(\n",
    "        \"徒歩\", \"\"\n",
    "    )\n",
    "    df_access.loc[\n",
    "        (\n",
    "            df_access[\"duration_1\"].str.contains(\"バス\")\n",
    "            | df_access[\"duration_1\"].str.contains(\"車\")\n",
    "        ),\n",
    "        [\"line_1\", \"station_1\", \"duration_1\"],\n",
    "    ] = [\"\", \"\", \"\"]\n",
    "    df_access.loc[:, \"station_1\"] = df_access[\"station_1\"].str.replace(\"駅\", \"\")\n",
    "    df_access.loc[:, \"duration_1\"] = (\n",
    "        df_access[\"duration_1\"]\n",
    "        .map(lambda x: np.nan if x == \"\" else x.replace(\"徒歩\", \"\").replace(\"分\", \"\"))\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    # 2つめの最寄り駅がバス/車の場合はNaNに\n",
    "    df_access.loc[:, \"duration_2\"] = df_access.loc[:, \"duration_2\"].map(\n",
    "        lambda x: \"\" if x is None else x\n",
    "    )\n",
    "    df_access.loc[\n",
    "        (\n",
    "            df_access[\"duration_2\"].str.contains(\"バス\")\n",
    "            | df_access[\"duration_2\"].str.contains(\"車\")\n",
    "        ),\n",
    "        [\"line_2\", \"station_2\", \"duration_2\"],\n",
    "    ] = [\"\", \"\", \"\"]\n",
    "    df_access.loc[:, \"station_2\"] = df_access[\"station_2\"].str.replace(\"駅\", \"\")\n",
    "    df_access.loc[:, \"duration_2\"] = (\n",
    "        df_access[\"duration_2\"]\n",
    "        .map(lambda x: np.nan if x == \"\" else x.replace(\"徒歩\", \"\").replace(\"分\", \"\"))\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    # 3つめの最寄り駅がバス/車の場合はNaNに\n",
    "    df_access.loc[:, \"duration_3\"] = df_access.loc[:, \"duration_3\"].map(\n",
    "        lambda x: \"\" if x is None else x\n",
    "    )\n",
    "    df_access.loc[\n",
    "        (\n",
    "            df_access[\"duration_3\"].str.contains(\"バス\")\n",
    "            | df_access[\"duration_3\"].str.contains(\"車\")\n",
    "        ),\n",
    "        [\"line_3\", \"station_3\", \"duration_3\"],\n",
    "    ] = [\"\", \"\", \"\"]\n",
    "    df_access.loc[:, \"station_3\"] = df_access[\"station_3\"].str.replace(\"駅\", \"\")\n",
    "    df_access.loc[:, \"duration_3\"] = (\n",
    "        df_access[\"duration_3\"]\n",
    "        .map(lambda x: np.nan if x == \"\" else x.replace(\"徒歩\", \"\").replace(\"分\", \"\"))\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    # 徒歩30分以上の場合は30分とする\n",
    "    df_access.loc[df_access.duration_1 > 30, \"duration_1\"] = 30\n",
    "    df_access.loc[df_access.duration_2 > 30, \"duration_2\"] = 30\n",
    "    df_access.loc[df_access.duration_3 > 30, \"duration_3\"] = 30\n",
    "\n",
    "    df = pd.concat([df, df_access], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 階建, 階\n",
    "def pre_kai(df):\n",
    "    def floor_map(x):\n",
    "\n",
    "        if type(x) == float:\n",
    "            return x\n",
    "\n",
    "        elif \"／\" not in x:\n",
    "            if \"階建\" in x:\n",
    "                return np.nan\n",
    "\n",
    "            else:\n",
    "                float(x.replace(\"階\", \"\"))\n",
    "\n",
    "        else:\n",
    "            if x.split(\"／\")[0] == \"\":\n",
    "                return np.nan\n",
    "            elif \"地下\" in x.split(\"／\")[0]:\n",
    "                return float(x.split(\"／\")[0].replace(\"階\", \"\").replace(\"地下\", \"-\"))\n",
    "            else:\n",
    "                return float(x.split(\"／\")[0].replace(\"階\", \"\"))\n",
    "\n",
    "    def stories(x):\n",
    "        if type(x) == float:\n",
    "            return x\n",
    "\n",
    "        elif len(x.split(\"／\")) == 2 and x.split(\"／\")[0] != \"\" and x.split(\"／\") != \"\":\n",
    "            return float(\n",
    "                x.split(\"／\")[1].replace(\"（\", \"(\").split(\"(地下\")[0].replace(\"階建\", \"\")\n",
    "            )\n",
    "\n",
    "    df.loc[:, \"floor\"] = df[\"所在階\"].map(floor_map)\n",
    "    df.loc[:, \"stories\"] = df[\"所在階\"].map(stories)\n",
    "    return df\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "def preprocessing(df):\n",
    "    df = rename_cols(df)\n",
    "    df = pre_area(df)\n",
    "    df = pre_age(df)\n",
    "    df = pre_ward(df)\n",
    "    df = pre_direction(df)\n",
    "    df = pre_madori(df)\n",
    "    df = pre_contract_period(df)\n",
    "    df = pre_access(df)\n",
    "    df = pre_kai(df)\n",
    "    df = pre_kitchen(df)\n",
    "    df = pre_bath(df)\n",
    "    df = pre_comm(df)\n",
    "    df = pre_room_equip(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Floor relative\n",
    "def fe_floor_relative(df):\n",
    "    df.loc[:, \"floor_relative\"] = df[\"floor\"] / df[\"stories\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df = fe_floor_relative(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical encoding\n",
    "\n",
    "# Use the number of feature as a feature\n",
    "def fe_count_all(df_train, df_test, cat_features=None):\n",
    "    for col in cat_features:\n",
    "        df_train[col + \"_countall\"] = df_train[col].map(\n",
    "            pd.concat([df_train[col], df_test[col]], ignore_index=True).value_counts(\n",
    "                dropna=False\n",
    "            )\n",
    "        )\n",
    "        df_test[col + \"_countall\"] = df_test[col].map(\n",
    "            pd.concat([df_train[col], df_test[col]], ignore_index=True).value_counts(\n",
    "                dropna=False\n",
    "            )\n",
    "        )\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "# Categorical Encoding\n",
    "def categorical_encoding(df, cat_features):\n",
    "    for col_name in cat_features:\n",
    "        df[col_name + \"_cat\"] = df[col_name].astype(\"category\").cat.codes\n",
    "    return df\n",
    "\n",
    "\n",
    "def dummy_cat_encoding(df, cat_features):\n",
    "    for col in cat_features:\n",
    "        t = pd.get_dummies(df[col])\n",
    "        t.columns = col + \"_\" + t.columns\n",
    "        df = pd.concat([df, t], axis=1)\n",
    "        df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_train = pd.read_csv(\"../input/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df_train = preprocessing(df_train)\n",
    "df_test = preprocessing(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df_train = feature_engineering(df_train)\n",
    "df_test = feature_engineering(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    \"ward\",\n",
    "    #     \"ward_detail\",\n",
    "    \"line_1\",\n",
    "    #     \"station_1\",\n",
    "    \"line_2\",\n",
    "    #     \"station_2\",\n",
    "    #     \"line_3\",\n",
    "    #     \"station_3\",\n",
    "    \"madori\",\n",
    "    \"direction\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count encoding\n",
    "df_train, df_test = fe_count_all(df_train, df_test, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Categorical Encoding\n",
    "df_train = dummy_cat_encoding(df_train, cat_features)\n",
    "df_test = dummy_cat_encoding(df_test, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN\n",
    "fill_na_cols = [\n",
    "    \"duration_1\",\n",
    "    \"duration_2\",\n",
    "    \"duration_3\",\n",
    "    \"floor\",\n",
    "    \"stories\",\n",
    "    \"floor_relative\",\n",
    "    \"contract_period\",\n",
    "    \"teiki_shakuya\",\n",
    "]\n",
    "for col in fill_na_cols:\n",
    "    df_train.loc[:, col] = df_train[col].fillna(-1)\n",
    "    df_test.loc[:, col] = df_test[col].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* 駅徒歩時間を最大値、最小値、平均値、駅の個数に分ける\n",
    "* 間取りを連続的な数値に\n",
    "* 最寄り駅の緯度経度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "drop_cols = [\n",
    "    \"アクセス\",\n",
    "    \"キッチン\",\n",
    "    \"バス・トイレ\",\n",
    "    \"周辺環境\",\n",
    "    \"契約期間\",\n",
    "    \"室内設備\",\n",
    "    \"建物構造\",\n",
    "    \"所在地\",\n",
    "    \"所在階\",\n",
    "    \"放送・通信\",\n",
    "    \"方角\",\n",
    "    \"築年数\",\n",
    "    \"間取り\",\n",
    "    \"面積\",\n",
    "    \"駐車場\",\n",
    "    #     \"direction\",\n",
    "    #     \"line_1\",\n",
    "    \"station_1\",\n",
    "    #     \"line_2\",\n",
    "    \"station_2\",\n",
    "    \"line_3\",\n",
    "    \"station_3\",\n",
    "    #     \"ward\",\n",
    "    \"ward_detail\",\n",
    "    #     \"madori\",\n",
    "    \"id\",\n",
    "]\n",
    "\n",
    "train = df_train.drop(drop_cols, axis=1, inplace=False)\n",
    "test = df_test.drop(drop_cols, axis=1, inplace=False)\n",
    "\n",
    "# Train Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    train.drop(\"target\", axis=1),\n",
    "    train.loc[:, \"target\"],\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return -np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "# model = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    train.drop(\"target\", axis=1),\n",
    "    train.loc[:, \"target\"],\n",
    "    n_jobs=5,\n",
    "    cv=5,\n",
    "    scoring=make_scorer(rmse, greater_is_better=False),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test.values, y_pred))\n",
    "print(\"RMSE:\", RMSE)\n",
    "\n",
    "# test_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores\n",
    "test_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "train_data = lgb.Dataset(x_train, y_train)\n",
    "test_data = lgb.Dataset(x_test, y_test)\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": -1,\n",
    "    \"num_leaves\": 255,\n",
    "    \"max_bin\": 255,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.8,\n",
    "    \"nthread\": -1,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"verbose\": -1,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, test_data],\n",
    "    num_boost_round=5000,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=200,\n",
    ")\n",
    "\n",
    "y_val_pred = model.predict(x_test)\n",
    "val_score = np.sqrt(mean_squared_error(y_test, y_val_pred))\n",
    "print(\"RMSE:\", val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame()\n",
    "feature_importances[\"feature\"] = x_train.columns\n",
    "feature_importances[\"importance\"] = model.feature_importance()\n",
    "feature_importances = feature_importances.sort_values(by=\"importance\", ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "sns.barplot(data=feature_importances.head(50), x=\"importance\", y=\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_test.loc[:, \"id\"], pd.Series(test_pred)], axis=1).to_csv(\n",
    "    \"./output/submission_{}.csv\".format(pd.to_datetime(\"today\").strftime(\"%Y-%m-%d\")),\n",
    "    header=False,\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
